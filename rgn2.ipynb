{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RGN Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original paper is at: https://www.biorxiv.org/content/biorxiv/early/2018/02/14/265231.full.pdf\n",
    "\n",
    "There are a lot of details missing, but the architecture is fairly simple. Feed sequences into an bi-LSTM and predict a set of three torsion angles. Pass the three predictions along with the current atoms for each residue into a \"geometric unit\", add each residue sequentially and deform the \"nascent structure\" appropriately. The last step is to calculate the loss, distance-based root mean square deviation (dRMSD), which accounts for global and local structural details and importantly does not require a specific orientation of the predicted structure since it only considers distance between pairs of atoms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ipywidgets as ip\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from collections import Counter as cs\n",
    "import sys\n",
    "import Bio.PDB as bio\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim\n",
    "import pdb\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "from data import ProteinDataset, sequence_collate\n",
    "from model import *\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.curdir + '/data/'\n",
    "pdb_path = os.curdir + '/data/pdb/structures/pdb/'\n",
    "encoding = 'tokens'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for creating new data subsets based on sequence lengths\n",
    "#sp = utils.subset(data_path+'proteins_1.bc', 150, 50, save_path=data_path+'proteins_short.bc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First construct the dataloader for training the model\n",
    "\n",
    "Know PDB file errors and issues:\n",
    "<ul>\n",
    "    <li>38 of 1992 chain_1 proteins have no coordinates, caused by weird files like pdb5da6.ent</li>\n",
    "    <li>some chain_1 proteins have hetatms in the main coordinate section because the residues are special transformations of the standard residue (i.e. selenomethionone in pdb1rfe.ent)</li>\n",
    "    <li>in 634 of 1992 chain_1 proteins the index of the last residue is greater than the number of residues in the sequence, because atoms in many files do not start at one (neither does sequence)</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_chains = '1' #1-8, number of chains in the protein\n",
    "dataset_size = len(bcolz.open(data_path+'proteins_{}.bc'.format(no_chains)))\n",
    "mask = np.random.random(dataset_size) < 0.8\n",
    "trn_ixs = np.arange(dataset_size)[mask]\n",
    "val_ixs = np.arange(dataset_size)[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dataset = ProteinDataset(data_path, '1', encoding=encoding, indices=trn_ixs)\n",
    "val_dataset = ProteinDataset(data_path, '1', encoding=encoding, indices=val_ixs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_data = DataLoader(trn_dataset, batch_size=32, shuffle=True, collate_fn=sequence_collate)\n",
    "val_data = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=sequence_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, torch.Size([895, 32]), torch.Size([2685, 32, 3]))\n",
      "(1, torch.Size([697, 32]), torch.Size([2091, 32, 3]))\n",
      "(2, torch.Size([746, 32]), torch.Size([2238, 32, 3]))\n",
      "(3, torch.Size([891, 32]), torch.Size([2673, 32, 3]))\n"
     ]
    }
   ],
   "source": [
    "for i_batch, sample_batched in enumerate(trn_data):\n",
    "    vec = sample_batched['sequence']\n",
    "    print(i_batch, sample_batched['sequence'].size(),\n",
    "         sample_batched['coords'].size())\n",
    "    if i_batch == 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RGN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RGN(nn.Module):\n",
    "    def __init__(self, hidden_size, num_layers, model_type='hardtanh', input_type='onehot', \n",
    "                 aa2vec=None, linear_units=None, input_size=21):\n",
    "        super(RGN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.input_type = input_type\n",
    "        self.model_type = model_type\n",
    "        self.grads = {}\n",
    "        \n",
    "        if self.input_type == 'onehot':\n",
    "            self.input_size = input_size\n",
    "        elif self.input_type == 'tokens':\n",
    "            self.embeds, vocab_sz, embed_dim = create_emb_layer(data_path + 'c3_embs.bc')\n",
    "            self.input_size = embed_dim + 1\n",
    "        \n",
    "        self.lstm = nn.LSTM(self.input_size, hidden_size, num_layers, bidirectional=True)\n",
    "        \n",
    "        if self.model_type == 'hardtanh':\n",
    "            self.linear1 = nn.Linear(hidden_size*2, 3)\n",
    "            self.linear2 = nn.Linear(hidden_size*2, 3)\n",
    "            self.hardtanh = nn.Hardtanh()\n",
    "        elif self.model_type == 'alphabet':\n",
    "            u = torch.distributions.Uniform(-3.14, 3.14)\n",
    "            self.alphabet = nn.Parameter(u.rsample(torch.Size([linear_units,3])))\n",
    "            self.linear = nn.Linear(hidden_size*2, linear_units)\n",
    "        \n",
    "        #set first coordinates to approximate values\n",
    "        self.A = torch.tensor([0.,0.,0.])\n",
    "        self.B = torch.tensor([1.384,-0.348,-0.463])\n",
    "        self.C = torch.tensor([1.920,0.789,-1.319])\n",
    "\n",
    "        #bond length vectors C-N, N-CA, CA-C\n",
    "        self.avg_bond_lens = torch.tensor([1.329, 1.459, 1.525])\n",
    "        #bond angle vector, in radians, CA-C-N, C-N-CA, N-CA-C\n",
    "        self.avg_bond_angles = torch.tensor([2.034, 2.119, 1.937])\n",
    "\n",
    "    \n",
    "    def forward(self, sequences, lengths):\n",
    "        max_len = sequences.size(0)\n",
    "        batch_sz = sequences.size(1)\n",
    "        lengths = torch.tensor(lengths, dtype=torch.long, requires_grad=False)\n",
    "        order = [x for x,y in sorted(enumerate(lengths), key=lambda x: x[1], reverse=True)]\n",
    "        \n",
    "        abs_pos = torch.tensor(range(max_len), dtype=torch.float32).unsqueeze(1)\n",
    "        abs_pos = (abs_pos * torch.ones((1, batch_sz))).unsqueeze(2)\n",
    "        \n",
    "        h0 = Variable(torch.zeros((self.num_layers*2, batch_sz, self.hidden_size)))\n",
    "        c0 = Variable(torch.zeros((self.num_layers*2, batch_sz, self.hidden_size)))\n",
    "        \n",
    "        #set sequence input type\n",
    "        if self.input_type == 'onehot':\n",
    "            sequences = torch.tensor(sequences, dtype=torch.float32, requires_grad=True)\n",
    "            pad_seq = torch.cat([sequences, abs_pos], 2)\n",
    "        elif self.input_type == 'tokens':\n",
    "            sequences = torch.tensor(sequences, dtype=torch.long, requires_grad=False)\n",
    "            pad_seq = self.embeds(sequences)\n",
    "            pad_seq = torch.cat([pad_seq, abs_pos], 2)\n",
    "    \n",
    "        packed = pack_padded_sequence(pad_seq[:, order], lengths[order], batch_first=False)\n",
    "        \n",
    "        lstm_out, _ = self.lstm(packed, (h0,c0))\n",
    "        unpacked, _ = pad_packed_sequence(lstm_out, batch_first=False, padding_value=0.0)\n",
    "        unpacked = unpacked[:, range(batch_sz)] #reorder to match target\n",
    "\n",
    "        if self.model_type == 'hardtanh':\n",
    "            sin_out = self.hardtanh(self.linear1(unpacked))\n",
    "            cos_out = self.hardtanh(self.linear2(unpacked))\n",
    "            out = torch.atan2(sin_out, cos_out)\n",
    "            #out.register_hook(self.save_grad('out'))\n",
    "        elif self.model_type == 'alphabet':\n",
    "            softmax_out = F.softmax(self.linear(unpacked), dim=2)\n",
    "            sine = torch.matmul(softmax_out, torch.sin(self.alphabet))\n",
    "            cosine = torch.matmul(softmax_out, torch.cos(self.alphabet))\n",
    "            out = torch.atan2(sine, cosine)\n",
    "        \n",
    "        #create as many copies of first residue as there are samples in the batch\n",
    "        broadcast = torch.ones((batch_sz, 3))\n",
    "        pred_coords = torch.stack([self.A*broadcast, self.B*broadcast, self.C*broadcast])\n",
    "        \n",
    "        for ix, triplet in enumerate(out[1:]):\n",
    "            pred_coords = geometric_unit(pred_coords, triplet, \n",
    "                                         self.avg_bond_angles, \n",
    "                                         self.avg_bond_lens)\n",
    "        #pred_coords.register_hook(self.save_grad('pc'))\n",
    "        \n",
    "            \n",
    "        #pdb.set_trace()\n",
    "        return pred_coords\n",
    "    \n",
    "    def save_grad(self, name):\n",
    "        def hook(grad): self.grads[name] = grad\n",
    "        return hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, torch.Size([597, 32]), torch.Size([1791, 32, 3]), torch.Size([1791, 32, 3]))\n",
      "(1, torch.Size([847, 32]), torch.Size([2541, 32, 3]), torch.Size([2541, 32, 3]))\n",
      "(2, torch.Size([1045, 32]), torch.Size([3135, 32, 3]), torch.Size([3135, 32, 3]))\n",
      "(3, torch.Size([941, 32]), torch.Size([2823, 32, 3]), torch.Size([2823, 32, 3]))\n"
     ]
    }
   ],
   "source": [
    "#make sure output size and target sizes are the same\n",
    "for i_batch, sampled_batch in enumerate(trn_data):\n",
    "    inp_seq = sampled_batch['sequence']\n",
    "    inp_lens = sampled_batch['length']\n",
    "    rgn = RGN(20, 1, 'hardtanh', encoding)\n",
    "    out = rgn(inp_seq, inp_lens)\n",
    "    print(i_batch, inp_seq.size(), sampled_batch['coords'].size(), out.size())\n",
    "    \n",
    "    if i_batch == 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgn = RGN(100, 1, 'hardtanh', encoding)\n",
    "#rgn.load_state_dict(torch.load(data_path+'models/rgn.pt')) #load pretrained model\n",
    "optimizer = torch.optim.Adam(rgn.parameters(), lr=1e-3)\n",
    "drmsd = dRMSD()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next steps, try debugging gradient using https://gist.github.com/apaszke/f93a377244be9bfcb96d3547b9bc424d."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "51it [06:45,  7.95s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train Loss 10.269399004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14it [00:45,  3.25s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Val Loss 8.76346907249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "51it [06:59,  8.22s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss 8.13909285545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14it [00:43,  3.13s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Val Loss 8.71808939714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "51it [06:16,  7.39s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train Loss 8.02683455467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14it [00:40,  2.87s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Val Loss 7.9209457911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "51it [06:20,  7.45s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train Loss 8.04145853996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14it [00:39,  2.85s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Val Loss 7.86673971323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "51it [06:18,  7.42s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss 7.91031151772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14it [00:40,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Val Loss 8.19588019298\n",
      "Finished Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "running_loss = 0.0\n",
    "last_batch = len(trn_data) - 2\n",
    "\n",
    "for epoch in range(5):\n",
    "    last_batch = len(trn_data) - 1\n",
    "    for i, data in tqdm(enumerate(trn_data)):\n",
    "        names = data['name']\n",
    "        coords = data['coords']\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = rgn(data['sequence'], data['length'])\n",
    "\n",
    "        loss = drmsd(outputs, coords)\n",
    "\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(rgn.parameters(), max_norm=50)\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if (i != 0) and (i % last_batch == 0):\n",
    "            print('Epoch {}, Train Loss {}'.format(epoch, running_loss/i))\n",
    "            running_loss = 0.0\n",
    "    \n",
    "    last_batch = len(val_data) - 1\n",
    "    for i, data in tqdm(enumerate(val_data)):\n",
    "        names = data['name']\n",
    "        coords = data['coords']\n",
    "        \n",
    "        outputs = rgn(data['sequence'], data['length'])\n",
    "        loss = drmsd(outputs, coords)\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if (i != 0) and (i % last_batch == 0):\n",
    "            print('Epoch {}, Val Loss {}'.format(epoch, running_loss/i))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(rgn.state_dict(), data_path+'models/rgn.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Geometric Units\n",
    "\n",
    "Some basic information about bond angles and lengths can be found here: https://www.ruppweb.org/Xray/tutorial/protein_structure.htm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "To validate that my implementation of the NERF algorithm is correct, I want to get pdb file, use BioPDB to calculate the torsion angles, and then use the ground truth torsion angles to reconstruct the coordinates. The goal is for the dRMSD between the rendered structure and the gt structure to be zero. This would imply that if my LSTM model can correctly predict the torsion angles the calculated coordinates should match the gt PDB file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#First find a pdb file with no missing coordinates\n",
    "chain_1 = load_array(data_path+'proteins_1.bc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "15\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "for ix, chain in enumerate(chain_1[:20]):\n",
    "    msk = chain[2].sum(1) == 0\n",
    "    if np.any(msk) == False:\n",
    "        print(ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1zur']"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_1[2][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Protein at index 2 in the proteins_1.bc dataset has no missing atoms, so we can use it for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "t_angles, b_angles, b_len = utils.gt_dihedral_angles(pdb_path+'pdb1zur.ent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Note that angles are in radians, whereas my implementation assumes degrees (can remove the 180 muliplication). Angles in omega are all roughly equal to $\\pi$ in accordance with literatue I've read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.3138,  0.2345,  0.9201])\n",
      "tensor([-0.3717,  0.2770, -0.8861])\n",
      "tensor([ 0.3293, -0.3031,  0.8942])\n"
     ]
    }
   ],
   "source": [
    "A = torch.tensor(chain_1[2][2][0], dtype=torch.float)\n",
    "B = torch.tensor(chain_1[2][2][1], dtype=torch.float)\n",
    "C = torch.tensor(chain_1[2][2][2], dtype=torch.float)\n",
    "\n",
    "#A = torch.tensor([0., 0., 1.], dtype=torch.float)\n",
    "#B = torch.tensor([0., 1., 0.], dtype=torch.float)\n",
    "#C = torch.tensor([1., 0., 0.], dtype=torch.float)\n",
    "\n",
    "#avg_bond_lens = torch.tensor([1.329, 1.459, 1.525])\n",
    "#avg_bond_angles = torch.tensor([2.034, 2.119, 1.937])\n",
    "\n",
    "pred_coords = torch.stack([A, B, C])\n",
    "\n",
    "for ix,triplet in enumerate(t_angles):\n",
    "    for i in range(3):\n",
    "        T = b_angles[ix][i] #avg_bond_angles[i] #angle_BCD\n",
    "        R = b_len[ix][i] #avg_bond_lens[i] #bond_CD\n",
    "        P = triplet[i] #torsionBC\n",
    "        \n",
    "        D2 = torch.stack([-R*torch.cos(T),\n",
    "                          R*torch.cos(P)*torch.sin(T),\n",
    "                          R*torch.sin(P)*torch.sin(T)])\n",
    "\n",
    "        BC = C - B\n",
    "        bc = BC/torch.norm(BC, 2)\n",
    "\n",
    "        AB = B - A\n",
    "\n",
    "        N = torch.cross(AB, bc)\n",
    "        n = N/torch.norm(torch.cross(AB, bc), 2)\n",
    "        \n",
    "        if ix==0:\n",
    "            print(n)\n",
    "\n",
    "        M = torch.stack([bc, torch.cross(n, bc), n], dim=1)\n",
    "\n",
    "        D = torch.mm(M, D2.view(-1,1)).squeeze() + C\n",
    "        \n",
    "        pred_coords = torch.cat([pred_coords, D.view(1,3)])\n",
    "        \n",
    "        A = pred_coords[-3]\n",
    "        B = pred_coords[-2]\n",
    "        C = pred_coords[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  1.4874,  2.5037,  3.6471,  4.9417,  6.0591,  7.2858],\n",
       "        [ 1.4874,  0.0000,  1.5289,  2.4205,  3.8290,  4.7594,  6.0301],\n",
       "        [ 2.5037,  1.5289,  0.0000,  1.3304,  2.4853,  3.6839,  4.8436],\n",
       "        [ 3.6471,  2.4205,  1.3304,  0.0000,  1.4620,  2.4165,  3.6473],\n",
       "        [ 4.9417,  3.8290,  2.4853,  1.4620,  0.0000,  1.5286,  2.4434],\n",
       "        [ 6.0591,  4.7594,  3.6839,  2.4165,  1.5286,  0.0000,  1.3305],\n",
       "        [ 7.2858,  6.0301,  4.8436,  3.6473,  2.4434,  1.3305,  0.0000]])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair_dist(pred_coords)[:7, :7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  1.4875,  2.5037,  3.6471,  4.9417,  6.0591,  7.2858],\n",
       "        [ 1.4875,  0.0000,  1.5288,  2.4205,  3.8289,  4.7595,  6.0301],\n",
       "        [ 2.5037,  1.5288,  0.0000,  1.3304,  2.4853,  3.6839,  4.8436],\n",
       "        [ 3.6471,  2.4205,  1.3304,  0.0000,  1.4620,  2.4165,  3.6473],\n",
       "        [ 4.9417,  3.8289,  2.4853,  1.4620,  0.0000,  1.5286,  2.4434],\n",
       "        [ 6.0591,  4.7595,  3.6839,  2.4165,  1.5286,  0.0000,  1.3305],\n",
       "        [ 7.2858,  6.0301,  4.8436,  3.6473,  2.4434,  1.3305,  0.0000]], dtype=torch.float64)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_coords = torch.tensor(chain_1[2][2])\n",
    "pair_dist(gt_coords)[:7, :7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Notice that there is a considerable amount of error injected into the geometric units when just using average bond lengths and angles. In particular, since bond lengths are fixed, it is actually impossible to train any model that can achieve zero loss (dRMSD is directly affected by the bond lengths). Using the identity matrix as Mohammed suggested also leads to larger errors even when using the gt torsions. I dislike the idea of lazily allowing these sources of loss to remain in the model, but I want to see if it is possible to reproduce the paper's results before jiggering with the architecture. At the very least, it seems like these parameters should be learnable."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda2]",
   "language": "python",
   "name": "conda-env-anaconda2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
