{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RGN Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most recent possibly useful paper that I could find is: https://www.biorxiv.org/content/biorxiv/early/2018/02/14/265231.full.pdf\n",
    "\n",
    "There are a lot of details missing so I expect that it will be difficult to implement, but the architecture is fairly simple. Feed sequence into an bi-LSTM and try to predict three bond characteristics (angle, extension and torsion). Pass the three predictions along with the current atoms for each residue into a \"geometric unit\", add each residue sequentially and deform the \"nascent structure\" appropriately. The last step is to calculate the loss, distance-based root mean square deviation (dRMSD), which accounts for global and local structural details and importantly does not require a specific orientation of the predicted structure since it only considers distance between one atom and all other atoms.\n",
    "\n",
    "For training data the author uses targets from CASP 1-10 and tests results on CASP 11."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task list:\n",
    "<ul>\n",
    "    <li>Create new bcolz array to attach sequence and structure together</li>\n",
    "    <li>Pad structures to match length of sequences</li>\n",
    "    <li>Handling of inaccurate PDB files</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ipywidgets as ip\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import collections\n",
    "from collections import Counter as cs\n",
    "#import nglview as nv\n",
    "import sys\n",
    "import Bio.PDB as bio\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import torch.optim\n",
    "import pdb\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "from data import ProteinDataset, sequence_collate\n",
    "from model import *\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.curdir + '/data/'\n",
    "pdb_path = os.curdir + '/data/pdb/structures/pdb/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sp = utils.subset(data_path+'proteins_1.bc', 150, 50, save_path=data_path+'proteins_short.bc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First construct the dataloader for training the model\n",
    "\n",
    "Know PDB file errors and issues:\n",
    "<ul>\n",
    "    <li>38 of 1992 chain_1 proteins have no coordinates, caused by weird files like pdb5da6.ent</li>\n",
    "    <li>some chain_1 proteins have hetatms in the main coordinate section because the residues are special transformations of the standard residue (i.e. selenomethionone in pdb1rfe.ent)</li>\n",
    "    <li>in 634 of 1992 chain_1 proteins the index of the last residue is greater than the number of residues in the sequence, because atoms in many files do not start at one (neither does sequence)</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ProteinDataset(data_path, 'short', encoding='onehot')\n",
    "trn_data = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=sequence_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, torch.Size([149, 32, 20]), torch.Size([447, 32, 3]))\n",
      "(1, torch.Size([142, 32, 20]), torch.Size([426, 32, 3]))\n",
      "(2, torch.Size([149, 32, 20]), torch.Size([447, 32, 3]))\n",
      "(3, torch.Size([148, 32, 20]), torch.Size([444, 32, 3]))\n"
     ]
    }
   ],
   "source": [
    "for i_batch, sample_batched in enumerate(trn_data):\n",
    "    vec = sample_batched['sequence']\n",
    "    print(i_batch, sample_batched['sequence'].size(),\n",
    "         sample_batched['coords'].size())\n",
    "    if i_batch == 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Potential todos with PDB data because of exceptions and errors:\n",
    "<ul>\n",
    "    <li>Atoms with multiple possible positions (A, B)</li>\n",
    "    <li>PDB files with multiple chains</li>\n",
    "    <li>Masking to use chains with atoms that don't have position 1</li>\n",
    "    <li>HETATMs like water can play a substantial role in the final folds</li>\n",
    "    <li>Consider adjusting loss function to reduce penalty for atoms with multiple occupancy</li>\n",
    "</ul>\n",
    "\n",
    "NOTE: Always make input tensor a float and wrap the input as an autograd variable!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RGN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aa2vec = bcolz.open(data_path + 'c3_embs.bc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RGN(nn.Module):\n",
    "    def __init__(self, hidden_size, num_layers, model_type='hardtanh', input_type='onehot', \n",
    "                 aa2vec=None, linear_units=None, input_size=21):\n",
    "        super(RGN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.input_type = input_type\n",
    "        self.model_type = model_type\n",
    "        self.grads = {}\n",
    "        \n",
    "        if self.input_type == 'onehot':\n",
    "            self.input_size = input_size\n",
    "        elif self.input_type == 'tokens':\n",
    "            self.input_size = aa2vec.shape[1] + 1\n",
    "            self.embeds, vocab_sz, embed_dim = create_emb_layer(data_path + 'c3_embs.bc')\n",
    "        \n",
    "        self.lstm = nn.LSTM(self.input_size, hidden_size, num_layers, bidirectional=True)\n",
    "        \n",
    "        if self.model_type == 'hardtanh':\n",
    "            self.linear1 = nn.Linear(hidden_size*2, 3)\n",
    "            self.linear2 = nn.Linear(hidden_size*2, 3)\n",
    "            self.hardtanh = nn.Hardtanh()\n",
    "        elif self.model_type == 'alphabet':\n",
    "            u = torch.distributions.Uniform(-3.14, 3.14)\n",
    "            self.alphabet = nn.Parameter(u.rsample(torch.Size([linear_units,3])))\n",
    "            self.linear = nn.Linear(hidden_size*2, linear_units)\n",
    "        \n",
    "        #as per Mohammed, we simply use the identity matrix to define the first 3 residues\n",
    "        #self.A = torch.tensor([0., 0., 1.])\n",
    "        #self.B = torch.tensor([0., 1., 0.])\n",
    "        #self.C = torch.tensor([1., 0., 0.])\n",
    "        self.A = torch.tensor([0.,0.,0.])\n",
    "        self.B = torch.tensor([1.384,-0.348,-0.463])\n",
    "        self.C = torch.tensor([1.920,0.789,-1.319])\n",
    "\n",
    "        #bond length vectors C-N, N-CA, CA-C\n",
    "        self.avg_bond_lens = torch.tensor([1.329, 1.459, 1.525])\n",
    "        #bond angle vector, in radians, CA-C-N, C-N-CA, N-CA-C\n",
    "        self.avg_bond_angles = torch.tensor([2.034, 2.119, 1.937])\n",
    "\n",
    "    \n",
    "    def forward(self, sequences, lengths):\n",
    "        max_len = sequences.size(0)\n",
    "        batch_sz = sequences.size(1)\n",
    "        lengths = torch.tensor(lengths, dtype=torch.long, requires_grad=False)\n",
    "        order = [x for x,y in sorted(enumerate(lengths), key=lambda x: x[1], reverse=True)]\n",
    "        \n",
    "        abs_pos = torch.tensor(range(max_len), dtype=torch.float32).unsqueeze(1)\n",
    "        abs_pos = (abs_pos * torch.ones((1, batch_sz))).unsqueeze(2)\n",
    "        \n",
    "        h0 = Variable(torch.zeros((self.num_layers*2, batch_sz, self.hidden_size)))\n",
    "        c0 = Variable(torch.zeros((self.num_layers*2, batch_sz, self.hidden_size)))\n",
    "        \n",
    "        #set sequence input type\n",
    "        if self.input_type == 'onehot':\n",
    "            sequences = torch.tensor(sequences, dtype=torch.float32, requires_grad=True)\n",
    "            pad_seq = torch.cat([sequences, abs_pos], 2)\n",
    "        elif self.input_type == 'tokens':\n",
    "            sequences = torch.tensor(sequences, dtype=torch.long, requires_grad=False)\n",
    "            pad_seq = self.embeds(sequences)\n",
    "            pad_seq = torch.cat([pad_seq, abs_pos], 2)\n",
    "    \n",
    "        packed = pack_padded_sequence(pad_seq[:, order], lengths[order], batch_first=False)\n",
    "        \n",
    "        lstm_out, _ = self.lstm(packed, (h0,c0))\n",
    "        unpacked, _ = pad_packed_sequence(lstm_out, batch_first=False, padding_value=0.0)\n",
    "        unpacked = unpacked[:, range(batch_sz)] #reorder to match target\n",
    "\n",
    "        if self.model_type == 'hardtanh':\n",
    "            sin_out = self.hardtanh(self.linear1(unpacked))\n",
    "            cos_out = self.hardtanh(self.linear2(unpacked))\n",
    "            out = torch.atan2(sin_out, cos_out)\n",
    "            #out.register_hook(self.save_grad('out'))\n",
    "        elif self.model_type == 'alphabet':\n",
    "            softmax_out = F.softmax(self.linear(unpacked), dim=2)\n",
    "            sine = torch.matmul(softmax_out, torch.sin(self.alphabet))\n",
    "            cosine = torch.matmul(softmax_out, torch.cos(self.alphabet))\n",
    "            out = torch.atan2(sine, cosine)\n",
    "        \n",
    "        #create as many copies of first residue as there are samples in the batch\n",
    "        broadcast = torch.ones((batch_sz, 3))\n",
    "        pred_coords = torch.stack([self.A*broadcast, self.B*broadcast, self.C*broadcast])\n",
    "        \n",
    "        for ix, triplet in enumerate(out[1:]):\n",
    "            pred_coords = geometric_unit(pred_coords, triplet, \n",
    "                                         self.avg_bond_angles, \n",
    "                                         self.avg_bond_lens)\n",
    "        #pred_coords.register_hook(self.save_grad('pc'))\n",
    "        \n",
    "            \n",
    "        #pdb.set_trace()\n",
    "        return pred_coords\n",
    "    \n",
    "    def save_grad(self, name):\n",
    "        def hook(grad): self.grads[name] = grad\n",
    "        return hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i_batch, sampled_batch in enumerate(trn_data):\n",
    "#    inp_seq = sampled_batch['sequence']\n",
    "#    inp_lens = sampled_batch['length']\n",
    "#    rgn = RGN(20, 1, 'hardtanh', 'onehot')\n",
    "#    out = rgn(inp_seq, inp_lens)\n",
    "#    print(i_batch, inp_seq.size(), sampled_batch['coords'].size(), out.size())\n",
    "    \n",
    "#    if i_batch == 1:\n",
    "#        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaptive_lr(optimizer, step_size):\n",
    "    #for now just linear scaling\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] += step_size\n",
    "        new_lr = param_group['lr']\n",
    "    \n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgn = RGN(800, 2, 'hardtanh', 'onehot', aa2vec=aa2vec)\n",
    "drmsd = dRMSD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = torch.optim.SGD(rgn.parameters(), lr=1e-1, momentum=0.9)\n",
    "#rgn.load_state_dict(torch.load(data_path+'models/rgn.pt'))\n",
    "optimizer = torch.optim.Adam(rgn.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next steps, try debugging gradient using https://gist.github.com/apaszke/f93a377244be9bfcb96d3547b9bc424d."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [06:01, 20.08s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss 43.1176270878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [06:01, 20.10s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss 17.2254386229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13it [04:25, 20.42s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-307-d883acc822bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrgn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sequence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'length'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdrmsd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m#print(i, loss.item(), rgn.embeds.state_dict()['weight'][0][0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/nbs/protein/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mco\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mco\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mxdist_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpair_dist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0mydist_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpair_dist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0mD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mydist_mat\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mxdist_mat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/nbs/protein/model.py\u001b[0m in \u001b[0;36mpair_dist\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0my_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_norm\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my_norm\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;31m#enforce all zeros along the diagonal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_history=[]\n",
    "running_loss = 0.0\n",
    "last_batch = len(trn_data) - 1\n",
    "c = 0\n",
    "for epoch in range(50):\n",
    "    #c = 0\n",
    "    for i, data in tqdm(enumerate(trn_data)):\n",
    "    #for i, data in enumerate(trn_data):\n",
    "        #try:\n",
    "        names = data['name']\n",
    "        coords = data['coords']\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = rgn(data['sequence'], data['length'])\n",
    "\n",
    "        loss = drmsd(outputs, coords)\n",
    "\n",
    "        #print(i, loss.item(), rgn.embeds.state_dict()['weight'][0][0])\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(rgn.parameters(), max_norm=1)\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if (i != 0) and (i % last_batch == 0):\n",
    "            print('Epoch {}, Loss {}'.format(epoch, running_loss/(i-c)))\n",
    "            running_loss = 0.0\n",
    "        #except KeyboardInterrupt:\n",
    "        #    raise\n",
    "        #except:\n",
    "        #    c += 1\n",
    "        #    pass\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(rgn.state_dict(), data_path+'models/rgn.pt')\n",
    "#rgn.load_state_dict(torch.load(data_path+'models/rgn.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(np.array(loss_history)[:, 0], np.array(loss_history)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.__version__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Validation\n",
    "\n",
    "To actually reproduce the results from the RGN paper, I need to use the proteinnet dataset, https://github.com/aqlaboratory/proteinnet. In particular, Mohammed used the CASP 11 data to test his model. The full dataset may be too large for my memory without deleting all the hard work I did with the pdb files. However, if I delete all the PDB files are currently have, I at least still have the tools to reproduce the datasets if necessary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Geometric Units\n",
    "\n",
    "Some basic information about bond angles and lengths can be found here: https://www.ruppweb.org/Xray/tutorial/protein_structure.htm\n",
    "\n",
    "I'll use this as my primary source, but it may be somewhat inaccurate (I have since found a more reliable source, saved in my Dropbox)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "To validate that my implementation of the NERF algorithm is correct, I want to get pdb file, use BioPDB to calculate the torsion angles, and then use the ground truth torsion angles to reconstruct the coordinates. The goal is for the dRMSD between the rendered structure and the gt structure to be zero. This would imply that if my LSTM model can correctly predict the torsion angles the calculated coordinates should match the gt PDB file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#First find a pdb file with no missing coordinates\n",
    "chain_1 = load_array(data_path+'proteins_1.bc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "15\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "for ix, chain in enumerate(chain_1[:20]):\n",
    "    msk = chain[2].sum(1) == 0\n",
    "    if np.any(msk) == False:\n",
    "        print(ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1zur']"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_1[2][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Protein at index 2 in the proteins_1.bc dataset has no missing atoms, so we can use it for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "t_angles, b_angles, b_len = utils.gt_dihedral_angles(pdb_path+'pdb1zur.ent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Note that angles are in radians, whereas my implementation assumes degrees (can remove the 180 muliplication). Angles in omega are all roughly equal to $\\pi$ in accordance with literatue I've read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.3138,  0.2345,  0.9201])\n",
      "tensor([-0.3717,  0.2770, -0.8861])\n",
      "tensor([ 0.3293, -0.3031,  0.8942])\n"
     ]
    }
   ],
   "source": [
    "A = torch.tensor(chain_1[2][2][0], dtype=torch.float)\n",
    "B = torch.tensor(chain_1[2][2][1], dtype=torch.float)\n",
    "C = torch.tensor(chain_1[2][2][2], dtype=torch.float)\n",
    "\n",
    "#A = torch.tensor([0., 0., 1.], dtype=torch.float)\n",
    "#B = torch.tensor([0., 1., 0.], dtype=torch.float)\n",
    "#C = torch.tensor([1., 0., 0.], dtype=torch.float)\n",
    "\n",
    "#avg_bond_lens = torch.tensor([1.329, 1.459, 1.525])\n",
    "#avg_bond_angles = torch.tensor([2.034, 2.119, 1.937])\n",
    "\n",
    "pred_coords = torch.stack([A, B, C])\n",
    "\n",
    "for ix,triplet in enumerate(t_angles):\n",
    "    for i in range(3):\n",
    "        T = b_angles[ix][i] #avg_bond_angles[i] #angle_BCD\n",
    "        R = b_len[ix][i] #avg_bond_lens[i] #bond_CD\n",
    "        P = triplet[i] #torsionBC\n",
    "        \n",
    "        D2 = torch.stack([-R*torch.cos(T),\n",
    "                          R*torch.cos(P)*torch.sin(T),\n",
    "                          R*torch.sin(P)*torch.sin(T)])\n",
    "\n",
    "        BC = C - B\n",
    "        bc = BC/torch.norm(BC, 2)\n",
    "\n",
    "        AB = B - A\n",
    "\n",
    "        N = torch.cross(AB, bc)\n",
    "        n = N/torch.norm(torch.cross(AB, bc), 2)\n",
    "        \n",
    "        if ix==0:\n",
    "            print(n)\n",
    "\n",
    "        M = torch.stack([bc, torch.cross(n, bc), n], dim=1)\n",
    "\n",
    "        D = torch.mm(M, D2.view(-1,1)).squeeze() + C\n",
    "        \n",
    "        pred_coords = torch.cat([pred_coords, D.view(1,3)])\n",
    "        \n",
    "        A = pred_coords[-3]\n",
    "        B = pred_coords[-2]\n",
    "        C = pred_coords[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  1.4874,  2.5037,  3.6471,  4.9417,  6.0591,  7.2858],\n",
       "        [ 1.4874,  0.0000,  1.5289,  2.4205,  3.8290,  4.7594,  6.0301],\n",
       "        [ 2.5037,  1.5289,  0.0000,  1.3304,  2.4853,  3.6839,  4.8436],\n",
       "        [ 3.6471,  2.4205,  1.3304,  0.0000,  1.4620,  2.4165,  3.6473],\n",
       "        [ 4.9417,  3.8290,  2.4853,  1.4620,  0.0000,  1.5286,  2.4434],\n",
       "        [ 6.0591,  4.7594,  3.6839,  2.4165,  1.5286,  0.0000,  1.3305],\n",
       "        [ 7.2858,  6.0301,  4.8436,  3.6473,  2.4434,  1.3305,  0.0000]])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair_dist(pred_coords)[:7, :7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  1.4875,  2.5037,  3.6471,  4.9417,  6.0591,  7.2858],\n",
       "        [ 1.4875,  0.0000,  1.5288,  2.4205,  3.8289,  4.7595,  6.0301],\n",
       "        [ 2.5037,  1.5288,  0.0000,  1.3304,  2.4853,  3.6839,  4.8436],\n",
       "        [ 3.6471,  2.4205,  1.3304,  0.0000,  1.4620,  2.4165,  3.6473],\n",
       "        [ 4.9417,  3.8289,  2.4853,  1.4620,  0.0000,  1.5286,  2.4434],\n",
       "        [ 6.0591,  4.7595,  3.6839,  2.4165,  1.5286,  0.0000,  1.3305],\n",
       "        [ 7.2858,  6.0301,  4.8436,  3.6473,  2.4434,  1.3305,  0.0000]], dtype=torch.float64)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_coords = torch.tensor(chain_1[2][2])\n",
    "pair_dist(gt_coords)[:7, :7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Notice that there is a considerable amount of error injected into the geometric units when just using average bond lengths and angles. In particular, since bond lengths are fixed, it is actually impossible to train any model that can achieve zero loss (dRMSD is directly affected by the bond lengths). Using the identity matrix as Mohammed suggested also leads to larger errors even when using the gt torsions. I dislike the idea of lazily allowing these sources of loss to remain in the model, but I want to see if it is possible to reproduce the paper's results before jiggering with the architecture. At the very least, it seems like these parameters should be learnable."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda2]",
   "language": "python",
   "name": "conda-env-anaconda2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
