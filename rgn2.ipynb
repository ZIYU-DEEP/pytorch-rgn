{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RGN Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most recent possibly useful paper that I could find is: https://www.biorxiv.org/content/biorxiv/early/2018/02/14/265231.full.pdf\n",
    "\n",
    "There are a lot of details missing so I expect that it will be difficult to implement, but the architecture is fairly simple. Feed sequence into an bi-LSTM and try to predict three bond characteristics (angle, extension and torsion). Pass the three predictions along with the current atoms for each residue into a \"geometric unit\", add each residue sequentially and deform the \"nascent structure\" appropriately. The last step is to calculate the loss, distance-based root mean square deviation (dRMSD), which accounts for global and local structural details and importantly does not require a specific orientation of the predicted structure since it only considers distance between one atom and all other atoms.\n",
    "\n",
    "For training data the author uses targets from CASP 1-10 and tests results on CASP 11."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task list:\n",
    "<ul>\n",
    "    <li>Create new bcolz array to attach sequence and structure together</li>\n",
    "    <li>Pad structures to match length of sequences</li>\n",
    "    <li>Handling of inaccurate PDB files</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ipywidgets as ip\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "#import utils\n",
    "from fastai import *\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import collections\n",
    "from collections import Counter as cs\n",
    "#import nglview as nv\n",
    "import sys\n",
    "import Bio.PDB as bio\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import torch.optim\n",
    "import pdb\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "from data import ProteinDataset, sequence_collate\n",
    "from model import geometric_unit, pair_dist, dRMSD\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [16,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.curdir + '/data/'\n",
    "#load sequence file as a bcolz array for the sake of space and speed\n",
    "#seq_file = load_array(data_path+'sequences.bc')\n",
    "pdb_path = os.curdir + '/data/pdb/structures/pdb/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trn_samp = load_array(data_path+'train_samples.dat')\n",
    "#val_samp = load_array(data_path+'validation_samples.dat')\n",
    "#tst_samp = load_array(data_path+'test_samples.dat')\n",
    "#keep = load_array(data_path+'keep.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = bcolz.carray(rootdir=data_path+'proteins_1.bc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for ix in range(len(c1)):\n",
    "#    name, _, _ = c1[ix]\n",
    "#    if name[0] == '2kw2':\n",
    "#        print(ix)\n",
    "#        break\n",
    "#sd = np.setdiff1d(range(len(c1)), [1916])\n",
    "#new_c1 = bcolz.carray(c1[sd], rootdir=data_path+'proteins_1.bc', mode='w')\n",
    "#new_c1.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "shix = []\n",
    "for ix in range(len(c1)):\n",
    "    name, sequence, coords = c1[ix]\n",
    "    length = len(sequence[0])\n",
    "    if (length > 100) and (length < 150):\n",
    "    #if length == 120:\n",
    "        shix.append(ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [],
   "source": [
    "shopro = bcolz.carray(c1[shix], rootdir=data_path+'proteins_short.bc', mode='w')\n",
    "shopro.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "354"
      ]
     },
     "execution_count": 551,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(shopro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First construct the dataloader for training the model\n",
    "\n",
    "Know PDB file errors and issues:\n",
    "<ul>\n",
    "    <li>38 of 1992 chain_1 proteins have no coordinates, caused by weird files like pdb5da6.ent</li>\n",
    "    <li>some chain_1 proteins have hetatms in the main coordinate section because the residues are special transformations of the standard residue (i.e. selenomethionone in pdb1rfe.ent)</li>\n",
    "    <li>in 634 of 1992 chain_1 proteins the index of the last residue is greater than the number of residues in the sequence, because atoms in many files do not start at one (neither does sequence)</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ProteinDataset(data_path, 'short', encoding='onehot')\n",
    "trn_data = DataLoader(dataset, batch_size=16, shuffle=True, collate_fn=sequence_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, torch.Size([148, 16, 20]), torch.Size([444, 16, 3]))\n",
      "(1, torch.Size([147, 16, 20]), torch.Size([441, 16, 3]))\n",
      "(2, torch.Size([149, 16, 20]), torch.Size([447, 16, 3]))\n",
      "(3, torch.Size([145, 16, 20]), torch.Size([435, 16, 3]))\n"
     ]
    }
   ],
   "source": [
    "for i_batch, sample_batched in enumerate(trn_data):\n",
    "    vec = sample_batched['sequence']\n",
    "    print(i_batch, sample_batched['sequence'].size(),\n",
    "         sample_batched['coords'].size())\n",
    "    if i_batch == 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Potential todos with PDB data because of exceptions and errors:\n",
    "<ul>\n",
    "    <li>Atoms with multiple possible positions (A, B)</li>\n",
    "    <li>PDB files with multiple chains</li>\n",
    "    <li>Masking to use chains with atoms that don't have position 1</li>\n",
    "    <li>HETATMs like water can play a substantial role in the final folds</li>\n",
    "    <li>Consider adjusting loss function to reduce penalty for atoms with multiple occupancy</li>\n",
    "</ul>\n",
    "\n",
    "NOTE: Always make input tensor a float and wrap the input as an autograd variable!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RGN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa2vec = bcolz.open(data_path + 'c3_embs.bc')\n",
    "\n",
    "def create_emb_layer(aa2vec):\n",
    "    aa2vec = torch.tensor(aa2vec, requires_grad=True)\n",
    "    vocab_sz, embed_dim = aa2vec.size()\n",
    "    emb_layer = nn.Embedding(vocab_sz, embed_dim)\n",
    "    emb_layer.load_state_dict({'weight': aa2vec})\n",
    "\n",
    "    return emb_layer, vocab_sz, embed_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RGN(nn.Module):\n",
    "    def __init__(self, hidden_size, num_layers, model_type='hardtanh', input_type='onehot', \n",
    "                 aa2vec=None, linear_units=None, input_size=21):\n",
    "        super(RGN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.input_type = input_type\n",
    "        self.model_type = model_type\n",
    "        self.grads = {}\n",
    "        \n",
    "        if self.input_type == 'onehot':\n",
    "            self.input_size = input_size\n",
    "        elif self.input_type == 'tokens':\n",
    "            self.input_size = aa2vec.shape[1]\n",
    "            self.embeds, vocab_sz, embed_dim = create_emb_layer(aa2vec)\n",
    "        \n",
    "        self.lstm = nn.LSTM(self.input_size, hidden_size, num_layers, bidirectional=True)\n",
    "        \n",
    "        if self.model_type == 'hardtanh':\n",
    "            self.linear1 = nn.Linear(hidden_size*2, 3)\n",
    "            self.linear2 = nn.Linear(hidden_size*2, 3)\n",
    "            self.hardtanh = nn.Hardtanh()\n",
    "        elif self.model_type == 'alphabet':\n",
    "            u = torch.distributions.Uniform(-3.14, 3.14)\n",
    "            self.alphabet = nn.Parameter(u.rsample(torch.Size([linear_units,3])))\n",
    "            self.linear = nn.Linear(hidden_size*2, linear_units)\n",
    "        \n",
    "        #as per Mohammed, we simply use the identity matrix to define the first 3 residues\n",
    "        self.A = torch.tensor([0., 0., 1.])\n",
    "        self.B = torch.tensor([0., 1., 0.])\n",
    "        self.C = torch.tensor([1., 0., 0.])\n",
    "\n",
    "        #bond length vectors C-N, N-CA, CA-C\n",
    "        self.avg_bond_lens = torch.tensor([1.329, 1.459, 1.525])\n",
    "        #bond angle vector, in radians, CA-C-N, C-N-CA, N-CA-C\n",
    "        self.avg_bond_angles = torch.tensor([2.034, 2.119, 1.937])\n",
    "\n",
    "    \n",
    "    def forward(self, sequences, lengths):\n",
    "        max_len = sequences.size(0)\n",
    "        batch_sz = sequences.size(1)\n",
    "        lengths = torch.tensor(lengths, dtype=torch.long, requires_grad=False)\n",
    "        order = [x for x,y in sorted(enumerate(lengths), key=lambda x: x[1], reverse=True)]\n",
    "        \n",
    "        abs_pos = torch.tensor(range(max_len), dtype=torch.float32).unsqueeze(1)\n",
    "        abs_pos = (abs_pos * torch.ones((1, batch_sz))).unsqueeze(2)\n",
    "        \n",
    "        h0 = Variable(torch.zeros((self.num_layers*2, batch_sz, self.hidden_size)))\n",
    "        c0 = Variable(torch.zeros((self.num_layers*2, batch_sz, self.hidden_size)))\n",
    "        \n",
    "        #set sequence input type\n",
    "        if self.input_type == 'onehot':\n",
    "            sequences = torch.tensor(sequences, dtype=torch.float32, requires_grad=True)\n",
    "            pad_seq = torch.cat([sequences, abs_pos], 2)\n",
    "        elif self.input_type == 'tokens':\n",
    "            sequences = torch.tensor(sequences, dtype=torch.long, requires_grad=False)\n",
    "            pad_seq = self.embeds(sequences)\n",
    "            pad_seq = torch.cat([pad_seq, abs_pos], 2)\n",
    "    \n",
    "        packed = pack_padded_sequence(pad_seq[:, order], lengths[order], batch_first=False)\n",
    "        \n",
    "        lstm_out, _ = self.lstm(packed, (h0,c0))\n",
    "        unpacked, _ = pad_packed_sequence(lstm_out, batch_first=False, padding_value=0.0)\n",
    "        unpacked = unpacked[:, range(batch_sz)] #reorder to match target\n",
    "        #unpacked.register_hook(self.save_grad('unpacked'))\n",
    "\n",
    "        if self.model_type == 'hardtanh':\n",
    "            sin_out = self.hardtanh(self.linear1(unpacked))\n",
    "            cos_out = self.hardtanh(self.linear2(unpacked))\n",
    "            #sin_out.register_hook(self.save_grad('sin_out'))\n",
    "            out = torch.atan2(sin_out, cos_out)\n",
    "            #out.register_hook(self.save_grad('out'))\n",
    "        elif self.model_type == 'alphabet':\n",
    "            softmax_out = F.softmax(self.linear(unpacked), dim=2)\n",
    "            sine = torch.matmul(softmax_out, torch.sin(self.alphabet))\n",
    "            cosine = torch.matmul(softmax_out, torch.cos(self.alphabet))\n",
    "            out = torch.atan2(sine, cosine)\n",
    "        \n",
    "        #create as many copies of first residue as there are samples in the batch\n",
    "        #broadcast = torch.ones((batch_sz, 3))\n",
    "        #pred_coords = torch.stack([self.A*broadcast, self.B*broadcast, self.C*broadcast])\n",
    "        \n",
    "        out = out.permute(dims=(1,0,2))\n",
    "        for num, seq in enumerate(out):\n",
    "            A, B, C = self.A, self.B, self.C\n",
    "            pcs = torch.stack([A, B, C])\n",
    "            for ix,triplet in enumerate(seq[1:]):\n",
    "                for i in range(3):\n",
    "                    #A, B, C = pred_coords[-3], pred_coords[-2], pred_coords[-1]\n",
    "                    T = self.avg_bond_angles[i] #angle_BCD\n",
    "                    R = self.avg_bond_lens[i] #bond_CD\n",
    "                    P = triplet[i] #torsionBC\n",
    "\n",
    "                    D2 = torch.stack([-R*torch.cos(T),\n",
    "                                      R*torch.cos(P)*torch.sin(T),\n",
    "                                      R*torch.sin(P)*torch.sin(T)])\n",
    "\n",
    "                    BC = C - B\n",
    "                    bc = BC/torch.norm(C - B, 2)\n",
    "\n",
    "                    AB = B - A\n",
    "\n",
    "                    N = torch.cross(AB, bc)\n",
    "                    n = N/torch.norm(torch.cross(AB, bc), 2)\n",
    "\n",
    "                    M = torch.stack([bc, torch.cross(n, bc), n], dim=1)\n",
    "\n",
    "                    D = torch.mm(M, D2.view(-1,1)).squeeze() + C\n",
    "                    pcs = torch.cat([pcs, D.view(1,3)])\n",
    "                    \n",
    "                    A = pcs[-3]\n",
    "                    B = pcs[-2]\n",
    "                    C = pcs[-1]\n",
    "            if num == 0:        \n",
    "                pred_coords = pcs\n",
    "            elif num == 1:\n",
    "                pred_coords = torch.stack([pred_coords, pcs], 1)\n",
    "            else:\n",
    "                pred_coords = torch.cat([pred_coords, pcs.unsqueeze(1)], 1)\n",
    "        #TODO: find bug in bmm (or maybe user error)\n",
    "        #for ix, triplet in enumerate(out[1:]):\n",
    "            #triplet.register_hook(self.save_grad('tr{}'.format(ix)))\n",
    "        #    pred_coords = geometric_unit(pred_coords, triplet, \n",
    "        #                                 self.avg_bond_angles, \n",
    "        #                                 self.avg_bond_lens)\n",
    "            #pred_coords.register_hook(self.save_grad('pc{}'.format(ix)))\n",
    "            \n",
    "        #pred_coords.register_hook(self.save_grad('pc'))\n",
    "            \n",
    "        #pdb.set_trace()\n",
    "        return pred_coords\n",
    "    \n",
    "    def save_grad(self, name):\n",
    "        def hook(grad): self.grads[name] = grad\n",
    "        return hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i_batch, sampled_batch in enumerate(trn_data):\n",
    "#    inp_seq = sampled_batch['sequence']\n",
    "#    inp_lens = sampled_batch['length']\n",
    "#    rgn = RGN(20, 1, 'hardtanh', 'onehot')\n",
    "#    out = rgn(inp_seq, inp_lens)\n",
    "#    print(i_batch, inp_seq.size(), sampled_batch['coords'].size(), out.size())\n",
    "    \n",
    "#    if i_batch == 1:\n",
    "#        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaptive_lr(optimizer, step_size):\n",
    "    #for now just linear scaling\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] += step_size\n",
    "        new_lr = param_group['lr']\n",
    "    \n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgn = RGN(200, 3, 'hardtanh', 'onehot')\n",
    "drmsd = dRMSD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(rgn.parameters(), lr=1e-3)\n",
    "#optimizer = torch.optim.Adam(rgn.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next steps, try debugging gradient using https://gist.github.com/apaszke/f93a377244be9bfcb96d3547b9bc424d."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "loss_history=[]\n",
    "running_loss = 0.0\n",
    "last_batch = len(trn_data) - 1\n",
    "c = 0\n",
    "for epoch in range(20):\n",
    "    c = 0\n",
    "    #for i, data in tqdm(enumerate(trn_data)):\n",
    "    for i, data in enumerate(trn_data):\n",
    "        try:\n",
    "            names = data['name']\n",
    "            coords = data['coords']\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = rgn(data['sequence'], data['length'])\n",
    "\n",
    "            loss = drmsd(outputs, coords)\n",
    "\n",
    "            #print(i, loss.item(), rgn.embeds.state_dict()['weight'][0][0])\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(rgn.parameters(), max_norm=1)\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            if (i != 0) and (i % last_batch == 0):\n",
    "                print('Epoch {}, Loss {}'.format(epoch, running_loss/(i-c)))\n",
    "                running_loss = 0.0\n",
    "        except KeyboardInterrupt:\n",
    "            raise\n",
    "        except:\n",
    "            c += 1\n",
    "            pass\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rgn.embeds.state_dict()['weight'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(rgn, data_path+'models/rgn1.pt')\n",
    "#rgn = torch.load(data_path+'models/rgn1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(np.array(loss_history)[:, 0], np.array(loss_history)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.__version__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Validation\n",
    "\n",
    "To actually reproduce the results from the RGN paper, I need to use the proteinnet dataset, https://github.com/aqlaboratory/proteinnet. In particular, Mohammed used the CASP 11 data to test his model. The full dataset may be too large for my memory without deleting all the hard work I did with the pdb files. However, if I delete all the PDB files are currently have, I at least still have the tools to reproduce the datasets if necessary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geometric Units\n",
    "\n",
    "Some basic information about bond angles and lengths can be found here: https://www.ruppweb.org/Xray/tutorial/protein_structure.htm\n",
    "\n",
    "I'll use this as my primary source, but it may be somewhat inaccurate (I have since found a more reliable source, saved in my Dropbox)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To validate that my implementation of the NERF algorithm is correct, I want to get pdb file, use BioPDB to calculate the torsion angles, and then use the ground truth torsion angles to reconstruct the coordinates. The goal is for the dRMSD between the rendered structure and the gt structure to be zero. This would imply that if my LSTM model can correctly predict the torsion angles the calculated coordinates should match the gt PDB file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First find a pdb file with no missing coordinates\n",
    "chain_1 = load_array(data_path+'proteins_1.bc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "15\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "for ix, chain in enumerate(chain_1[:20]):\n",
    "    msk = chain[2].sum(1) == 0\n",
    "    if np.any(msk) == False:\n",
    "        print(ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1zur']"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_1[2][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Protein at index 2 in the proteins_1.bc dataset has no missing atoms, so we can use it for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_angles, b_angles, b_len = utils.gt_dihedral_angles(pdb_path+'pdb1zur.ent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that angles are in radians, whereas my implementation assumes degrees (can remove the 180 muliplication). Angles in omega are all roughly equal to $\\pi$ in accordance with literatue I've read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "A = torch.tensor(chain_1[2][2][0], dtype=torch.float)\n",
    "B = torch.tensor(chain_1[2][2][1], dtype=torch.float)\n",
    "C = torch.tensor(chain_1[2][2][2], dtype=torch.float)\n",
    "\n",
    "#A = torch.tensor([0., 0., 1.], dtype=torch.float)\n",
    "#B = torch.tensor([0., 1., 0.], dtype=torch.float)\n",
    "#C = torch.tensor([1., 0., 0.], dtype=torch.float)\n",
    "\n",
    "#avg_bond_lens = torch.tensor([1.329, 1.459, 1.525])\n",
    "#avg_bond_angles = torch.tensor([2.034, 2.119, 1.937])\n",
    "\n",
    "pred_coords = torch.stack([A, B, C])\n",
    "\n",
    "for ix,triplet in enumerate(t_angles):\n",
    "    for i in range(3):\n",
    "        T = b_angles[ix][i] #avg_bond_angles[i] #angle_BCD\n",
    "        R = b_len[ix][i] #avg_bond_lens[i] #bond_CD\n",
    "        P = triplet[i] #torsionBC\n",
    "        \n",
    "        D2 = torch.stack([-R*torch.cos(T),\n",
    "                          R*torch.cos(P)*torch.sin(T),\n",
    "                          R*torch.sin(P)*torch.sin(T)])\n",
    "\n",
    "        BC = C - B\n",
    "        bc = BC/torch.norm(C - B, 2)\n",
    "\n",
    "        AB = B - A\n",
    "\n",
    "        N = torch.cross(AB, bc)\n",
    "        n = N/torch.norm(torch.cross(AB, bc), 2)\n",
    "\n",
    "        M = torch.stack([bc, torch.cross(n, bc), n], dim=1)\n",
    "\n",
    "        D = torch.mm(M, D2.view(-1,1)).squeeze() + C\n",
    "        pred_coords = torch.cat([pred_coords, D.view(1,3)])\n",
    "        \n",
    "        A = pred_coords[-3]\n",
    "        B = pred_coords[-2]\n",
    "        C = pred_coords[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  1.4874,  2.5037,  3.6471,  4.9417],\n",
       "        [ 1.4874,  0.0000,  1.5289,  2.4205,  3.8290],\n",
       "        [ 2.5037,  1.5289,  0.0000,  1.3304,  2.4853],\n",
       "        [ 3.6471,  2.4205,  1.3304,  0.0000,  1.4620],\n",
       "        [ 4.9417,  3.8290,  2.4853,  1.4620,  0.0000]])"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair_dist(pred_coords[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[]]\n"
     ]
    }
   ],
   "source": [
    "gt_coords = utils.create_targets(pdb_path+'pdb1zur.ent')\n",
    "print(gt_coords)\n",
    "#pair_dist(gt_coords[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that there is a considerable amount of error injected into the geometric units when just using average bond lengths and angles. In particular, since bond lengths are fixed, it is actually impossible to train any model that can achieve zero loss (dRMSD is directly affected by the bond lengths). Using the identity matrix as Mohammed suggested also leads to larger errors even when using the gt torsions. I dislike the idea of lazily allowing these sources of loss to remain in the model, but I want to see if it is possible to reproduce the paper's results before jiggering with the architecture. At the very least, it seems like these parameters should be learnable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Parse PDB files\n",
    "\n",
    "The target for each protein structure is the distance between one atom and all the others. The only atoms that are used are the  N, Cα, and C' for each residue. So if a protein sequence has 100 residues the target should be a 300x300 matrix. \n",
    "\n",
    "To start I think that I need to restrict myself to single chain proteins because it seems like multi-chain proteins need to be post-processed.\n",
    "\n",
    "Alphabet matrix: http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.122.1578&rep=rep1&type=pdf\n",
    "\n",
    "Torsion space conversion: https://pdfs.semanticscholar.org/6310/0da463862f35f4188754bdeb7f41e24dbfb7.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#import warnings\n",
    "#warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#keep = []\n",
    "#for ix,s in tqdm(enumerate(trn_samp)):\n",
    "#p = bio.PDBParser()\n",
    "#structure = p.get_structure('X', pdb_path+'pdb1rfe.ent')\n",
    "\n",
    "#for model in structure:\n",
    "#    for chain in model:\n",
    "#        for ix, residue in enumerate(chain):\n",
    "#            if residue.get_id()[0] == ' ':\n",
    "                #print(residue.get_id()[1])\n",
    "#                if ix == 0:\n",
    "#                    ex = residue.get_id()[1]  \n",
    "#                elif residue.get_id()[1] == ex+1:\n",
    "#                    ex = residue.get_id()[1]\n",
    "#                else:\n",
    "#                    print(\"error at {}\".format(residue.get_id()[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## LSTM example\n",
    "\n",
    "Try the example from http://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f6ad4d41b70>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Variable containing:\n",
       " -0.1186  0.4903  0.8349\n",
       " [torch.FloatTensor of size 1x3], Variable containing:\n",
       "  0.8894  0.4148  0.0507\n",
       " [torch.FloatTensor of size 1x3], Variable containing:\n",
       " -0.9644 -2.0111  0.5245\n",
       " [torch.FloatTensor of size 1x3], Variable containing:\n",
       "  2.1332 -0.0822  0.8388\n",
       " [torch.FloatTensor of size 1x3], Variable containing:\n",
       " -1.3233  0.0701  1.2200\n",
       " [torch.FloatTensor of size 1x3]]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm = BiLSTM(3,3,1)\n",
    "inputs = [Variable(torch.randn((1,3))) for _ in range(5)]\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiLSTM (\n",
       "  (lstm): LSTM(3, 3)\n",
       ")"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       " (0 ,.,.) = \n",
       "   0.4251 -1.2328 -0.6195\n",
       " [torch.FloatTensor of size 1x1x3], Variable containing:\n",
       " (0 ,.,.) = \n",
       "   1.5133  1.9954 -0.6585\n",
       " [torch.FloatTensor of size 1x1x3])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden = (Variable(torch.randn((1,1,3))), \n",
    "         Variable(torch.randn((1,1,3))))\n",
    "hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#for i in inputs:\n",
    "#    out, h = lstm.forward(i.view(1,1,-1), hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       " (0 ,.,.) = \n",
       "   0.4251 -1.2328 -0.6195\n",
       " [torch.FloatTensor of size 1x1x3], Variable containing:\n",
       " (0 ,.,.) = \n",
       "   1.5133  1.9954 -0.6585\n",
       " [torch.FloatTensor of size 1x1x3])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "(0 ,.,.) = \n",
       " -0.1186  0.4903  0.8349\n",
       "\n",
       "(1 ,.,.) = \n",
       "  0.8894  0.4148  0.0507\n",
       "\n",
       "(2 ,.,.) = \n",
       " -0.9644 -2.0111  0.5245\n",
       "\n",
       "(3 ,.,.) = \n",
       "  2.1332 -0.0822  0.8388\n",
       "\n",
       "(4 ,.,.) = \n",
       " -1.3233  0.0701  1.2200\n",
       "[torch.FloatTensor of size 5x1x3]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = torch.cat(inputs).view(len(inputs), 1, 3)\n",
    "hidden = (Variable(torch.randn((1,1,3))), \n",
    "         Variable(torch.randn((1,1,3))))\n",
    "#out, hidden = lstm(inputs, hidden)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "(0 ,.,.) = \n",
       "  0.6133 -0.2240  1.8343\n",
       "\n",
       "(1 ,.,.) = \n",
       " -0.1765  0.6837  1.2409\n",
       "\n",
       "(2 ,.,.) = \n",
       " -0.3073 -1.0962  1.6789\n",
       "\n",
       "(3 ,.,.) = \n",
       "  0.2860 -0.4774 -0.1175\n",
       "\n",
       "(4 ,.,.) = \n",
       "  0.1739 -0.1030 -0.5680\n",
       "[torch.FloatTensor of size 5x1x3]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       " (0 ,.,.) = \n",
       "  -0.3807 -0.2034 -0.2926\n",
       " [torch.FloatTensor of size 1x1x3], Variable containing:\n",
       " (0 ,.,.) = \n",
       "  -0.7260 -0.3826 -0.8743\n",
       " [torch.FloatTensor of size 1x1x3])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "(0 ,.,.) = \n",
       " -0.0823  0.0944 -0.1291\n",
       "\n",
       "(1 ,.,.) = \n",
       " -0.0851 -0.1749 -0.0420\n",
       "\n",
       "(2 ,.,.) = \n",
       " -0.1065 -0.3703 -0.0488\n",
       "\n",
       "(3 ,.,.) = \n",
       " -0.2781 -0.2692 -0.2353\n",
       "\n",
       "(4 ,.,.) = \n",
       " -0.3807 -0.2034 -0.2926\n",
       "[torch.FloatTensor of size 5x1x3]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Pad Packed Example\n",
    "Try the example from https://discuss.pytorch.org/t/simple-working-example-how-to-use-packing-for-variable-length-sequence-inputs-for-rnn/2120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=Variable containing:\n",
       " 1  2  3\n",
       " 1  2  0\n",
       " 1  0  0\n",
       "[torch.FloatTensor of size 3x3]\n",
       ", batch_sizes=[3])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 3\n",
    "max_length = 3\n",
    "hidden_size = 2\n",
    "n_layers = 1\n",
    "\n",
    "batch_in = torch.zeros((batch_size, 1, max_length))\n",
    "\n",
    "vec_1 = torch.FloatTensor([[1,2,3]])\n",
    "vec_2 = torch.FloatTensor([[1,2,0]])\n",
    "vec_3 = torch.FloatTensor([[1,0,0]])\n",
    "\n",
    "batch_in[0] = vec_1\n",
    "batch_in[1] = vec_2\n",
    "batch_in[2] = vec_3\n",
    "\n",
    "batch_in = Variable(batch_in)\n",
    "\n",
    "seq_lengths = [3,2,1]\n",
    "\n",
    "pack = nn.utils.rnn.pack_padded_sequence(batch_in, seq_lengths, batch_first=True)\n",
    "\n",
    "pack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "(0 ,.,.) = \n",
       " -0.7852 -0.9670\n",
       "  0.1932 -0.7175\n",
       " -0.8542 -0.4358\n",
       "[torch.FloatTensor of size 1x3x2]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm = nn.RNN(max_length, hidden_size, n_layers, batch_first=True)\n",
    "h0 = Variable(torch.randn(n_layers, batch_size, hidden_size))\n",
    "out, _ = lstm(pack, h0)\n",
    "unpacked, unpacked_len = nn.utils.rnn.pad_packed_sequence(out)\n",
    "unpacked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Loss Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class _Loss(nn.Module):\n",
    "    def __init__(self, size_average=True, reduce=True):\n",
    "        super(_Loss, self).__init__()\n",
    "        self.size_average = size_average\n",
    "        self.reduce = reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def _assert_no_grad(tensor):\n",
    "    assert not tensor.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def _pairwise_loss(lambd, input, target, size_average=True, reduce=True):\n",
    "    #if target.requires_grad:\n",
    "    d = lambd(input, target)\n",
    "    return d\n",
    "        #if not reduce:\n",
    "        #    return d\n",
    "        #return torch.mean(d) if size_average else torch.sum(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def batch_pair_dist(x, y=None):\n",
    "    x = x.permute(dims=(1,0,2))\n",
    "    x_norm = (x**2).sum(2).view(x.size(0), -1, 1)\n",
    "    \n",
    "    y_t = x.permute(0,2,1)\n",
    "    y_norm = x_norm.view(x.size(0), 1, -1)\n",
    "    \n",
    "    dist = x_norm + y_norm - 2*torch.bmm(x, y_t)\n",
    "    dist = torch.clamp(dist, 0.0, np.inf)\n",
    "    \n",
    "    return torch.pow(dist, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def drmsd_loss(input, target, size_average=True, reduce=True):\n",
    "    return _pairwise_loss(lambda a,b: batch_pair_dist(a,b), input, target, size_average, reduce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class dRMSDLoss(_Loss):\n",
    "    def __init__(self, size_average=True, reduce=True):\n",
    "        super(dRMSDLoss, self).__init__(size_average, reduce)\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        _assert_no_grad(target)\n",
    "        return drmsd_loss(input, target, size_average=self.size_average, reduce=self.reduce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "$ Torch: not enough memory: you tried to allocate 1GB. Buy new RAM! at /opt/conda/conda-bld/pytorch-cpu_1524577316810/work/aten/src/TH/THGeneral.c:218",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/IPython/core/formatters.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    697\u001b[0m                 \u001b[0mtype_pprinters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_printers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 deferred_pprinters=self.deferred_printers)\n\u001b[0;32m--> 699\u001b[0;31m             \u001b[0mprinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m             \u001b[0mprinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/IPython/lib/pretty.pyc\u001b[0m in \u001b[0;36mpretty\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    396\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m                                 \u001b[0;32mreturn\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_default_pprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/IPython/lib/pretty.pyc\u001b[0m in \u001b[0;36m_default_pprint\u001b[0;34m(obj, p, cycle)\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_safe_getattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mklass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__repr__'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_baseclass_reprs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0;31m# A user-provided repr. Find newlines and replace them with p.break_()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m         \u001b[0m_repr_pprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'<'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/IPython/lib/pretty.pyc\u001b[0m in \u001b[0;36m_repr_pprint\u001b[0;34m(obj, p, cycle)\u001b[0m\n\u001b[1;32m    707\u001b[0m     \u001b[0;34m\"\"\"A pprint that just redirects to the normal repr function.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m     \u001b[0;31m# Find newlines and replace them with p.break_()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_line\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/torch/tensor.pyc\u001b[0m in \u001b[0;36m__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'encoding'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m                 return torch._tensor_str._str(self).encode(\n\u001b[0m\u001b[1;32m     61\u001b[0m                     sys.stdout.encoding or 'UTF-8', 'replace')\n\u001b[1;32m     62\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/torch/_tensor_str.pyc\u001b[0m in \u001b[0;36m_str\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0msuffix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m', dtype='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0mfmt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_number_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mscale\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mSCALE_FORMAT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' '\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/torch/_tensor_str.pyc\u001b[0m in \u001b[0;36m_number_format\u001b[0;34m(tensor, min_sz)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0m_min_log_scale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_min_log_scale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0mmin_sz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_sz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDoubleTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnelement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mpos_inf_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'inf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: $ Torch: not enough memory: you tried to allocate 1GB. Buy new RAM! at /opt/conda/conda-bld/pytorch-cpu_1524577316810/work/aten/src/TH/THGeneral.c:218"
     ]
    }
   ],
   "source": [
    "drmsd_loss(out, Variable(sampled_batch['coords'], requires_grad=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "$ Torch: not enough memory: you tried to allocate 0GB. Buy new RAM! at /opt/conda/conda-bld/pytorch-cpu_1524577316810/work/aten/src/TH/THGeneral.c:218",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-202-dd146ffeae61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdRMSDLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampled_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'coords'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-196-3b001a27a46d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0m_assert_no_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdrmsd_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-195-d4eaad8e643c>\u001b[0m in \u001b[0;36mdrmsd_loss\u001b[0;34m(input, target, size_average, reduce)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdrmsd_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_pairwise_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_pair_dist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-193-0e3bed7cb8f4>\u001b[0m in \u001b[0;36m_pairwise_loss\u001b[0;34m(lambd, input, target, size_average, reduce)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_pairwise_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlambd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m#if target.requires_grad:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlambd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;31m#if not reduce:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-195-d4eaad8e643c>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdrmsd_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_pairwise_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_pair_dist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-194-342d46265df2>\u001b[0m in \u001b[0;36mbatch_pair_dist\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0my_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_norm\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my_norm\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: $ Torch: not enough memory: you tried to allocate 0GB. Buy new RAM! at /opt/conda/conda-bld/pytorch-cpu_1524577316810/work/aten/src/TH/THGeneral.c:218"
     ]
    }
   ],
   "source": [
    "loss = dRMSDLoss()\n",
    "loss(out, sampled_batch['coords'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Folding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from torch.autograd import gradcheck, Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Fold(Function):\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctx, pred_coords, pred_torsions, bond_angles, bond_lens):\n",
    "        \n",
    "    @staticmethod    \n",
    "    def backward(ctx, grad_output):\n",
    "\n",
    "def geometric_unit(pred_coords, pred_torsions, bond_angles, bond_lens):\n",
    "    for i in range(3):\n",
    "        #coordinates of last three atoms\n",
    "        A, B, C = pred_coords[-3], pred_coords[-2], pred_coords[-1]\n",
    "\n",
    "        #internal coordinates\n",
    "        T = bond_angles[i]\n",
    "        R = bond_lens[i]\n",
    "        P = pred_torsions[:, i]\n",
    "\n",
    "        #6x3 one triplet for each sample in the batch\n",
    "        D2 = torch.stack([-R*torch.ones(P.size())*torch.cos(T), \n",
    "                          R*torch.cos(P)*torch.sin(T),\n",
    "                          R*torch.sin(P)*torch.sin(T)], dim=1)\n",
    "\n",
    "        #6x3 one triplet for each sample in the batch\n",
    "        BC = C - B\n",
    "        bc = BC/torch.norm(BC, 2)\n",
    "\n",
    "        AB = B - A\n",
    "\n",
    "        N = torch.cross(AB, bc)\n",
    "        n = N/torch.norm(N, 2)\n",
    "\n",
    "        M = torch.stack([bc, torch.cross(n, bc), n], dim=2)\n",
    "\n",
    "        D = torch.bmm(M, D2.view(-1,3,1)).squeeze() + C\n",
    "        pred_coords = torch.cat([pred_coords, D.view(1,-1,3)])\n",
    "    \n",
    "    return pred_coords"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda2]",
   "language": "python",
   "name": "conda-env-anaconda2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
