{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RGN Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original paper is at: https://www.biorxiv.org/content/biorxiv/early/2018/02/14/265231.full.pdf\n",
    "\n",
    "There are a lot of details missing, but the architecture is fairly simple. Feed sequences into an bi-LSTM and predict a set of three torsion angles. Pass the three predictions along with the current atoms for each residue into a \"geometric unit\", add each residue sequentially and deform the \"nascent structure\" appropriately. The last step is to calculate the loss, distance-based root mean square deviation (dRMSD), which accounts for global and local structural details and importantly does not require a specific orientation of the predicted structure since it only considers distance between pairs of atoms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ipywidgets as ip\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from collections import Counter as cs\n",
    "import sys\n",
    "import Bio.PDB as bio\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim\n",
    "import pdb\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "from data import ProteinDataset, ProteinNet, sequence_collate\n",
    "from model import *\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.curdir + '/data/'\n",
    "pdb_path = os.curdir + '/data/pdb/structures/pdb/'\n",
    "encoding = 'onehot'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t = bcolz.carray(rootdir=data_path+'train30.bc')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for creating new data subsets based on sequence lengths\n",
    "#sp = utils.subset(data_path+'proteins_1.bc', 150, 50, save_path=data_path+'proteins_short.bc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Pytorch Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "First construct the dataloader for training the model\n",
    "\n",
    "Know PDB file errors and issues:\n",
    "<ul>\n",
    "    <li>38 of 1992 chain_1 proteins have no coordinates, caused by weird files like pdb5da6.ent</li>\n",
    "    <li>some chain_1 proteins have hetatms in the main coordinate section because the residues are special transformations of the standard residue (i.e. selenomethionone in pdb1rfe.ent)</li>\n",
    "    <li>in 634 of 1992 chain_1 proteins the index of the last residue is greater than the number of residues in the sequence, because atoms in many files do not start at one (neither does sequence)</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "no_chains = '1' #1-8, number of chains in the protein\n",
    "dataset_size = len(bcolz.open(data_path+'proteins_{}.bc'.format(no_chains)))\n",
    "mask = np.random.random(dataset_size) < 0.8\n",
    "trn_ixs = np.arange(dataset_size)[mask]\n",
    "val_ixs = np.arange(dataset_size)[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trn_dataset = ProteinNet(data_path+'train30.bc')\n",
    "val_dataset = ProteinNet(data_path+'validation.bc')\n",
    "#trn_dataset = ProteinDataset(data_path+'proteins_1.bc', encoding=encoding, indices=trn_ixs)\n",
    "#val_dataset = ProteinDataset(data_path+'proteins_1.bc', encoding=encoding, indices=val_ixs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trn_data = DataLoader(trn_dataset, batch_size=32, shuffle=True, collate_fn=sequence_collate)\n",
    "val_data = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=sequence_collate)\n",
    "#trn_data = DataLoader(trn_dataset, batch_size=32, shuffle=True, collate_fn=sequence_collate)\n",
    "#val_data = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=sequence_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, torch.Size([322, 32, 41]), torch.Size([966, 32, 3]))\n",
      "(1, torch.Size([695, 32, 41]), torch.Size([2085, 32, 3]))\n",
      "(2, torch.Size([731, 32, 41]), torch.Size([2193, 32, 3]))\n",
      "(3, torch.Size([450, 32, 41]), torch.Size([1350, 32, 3]))\n"
     ]
    }
   ],
   "source": [
    "for i_batch, sample_batched in enumerate(trn_data):\n",
    "    vec = sample_batched['sequence']\n",
    "    print(i_batch, sample_batched['sequence'].size(),\n",
    "         sample_batched['coords'].size())\n",
    "    if i_batch == 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([395, 32])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_batched['mask'].size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RGN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RGN(nn.Module):\n",
    "    def __init__(self, hidden_size, num_layers, model_type='hardtanh', input_type='onehot', \n",
    "                 aa2vec=None, linear_units=None, input_size=42):\n",
    "        super(RGN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.input_type = input_type\n",
    "        self.model_type = model_type\n",
    "        self.grads = {}\n",
    "        \n",
    "        if self.input_type == 'onehot':\n",
    "            self.input_size = input_size\n",
    "        elif self.input_type == 'tokens':\n",
    "            self.embeds, vocab_sz, embed_dim = create_emb_layer(data_path + 'c3_embs.bc')\n",
    "            self.input_size = embed_dim + 1\n",
    "        \n",
    "        self.lstm = nn.LSTM(self.input_size, hidden_size, num_layers, bidirectional=True)\n",
    "        \n",
    "        if self.model_type == 'hardtanh':\n",
    "            self.linear1 = nn.Linear(hidden_size*2, 3)\n",
    "            self.bn1 = nn.BatchNorm1d(3)\n",
    "            self.linear2 = nn.Linear(hidden_size*2, 3)\n",
    "            self.bn2 = nn.BatchNorm1d(3)\n",
    "            self.hardtanh = nn.Hardtanh()\n",
    "        elif self.model_type == 'alphabet':\n",
    "            u = torch.distributions.Uniform(-3.14, 3.14)\n",
    "            self.alphabet = nn.Parameter(u.rsample(torch.Size([linear_units,3])))\n",
    "            self.linear = nn.Linear(hidden_size*2, linear_units)\n",
    "        \n",
    "        #set first coordinates to approximate values\n",
    "        self.A = torch.tensor([0.,0.,0.])\n",
    "        self.B = torch.tensor([1.384,-0.348,-0.463])\n",
    "        self.C = torch.tensor([1.920,0.789,-1.319])\n",
    "\n",
    "        #bond length vectors C-N, N-CA, CA-C\n",
    "        self.avg_bond_lens = torch.tensor([1.329, 1.459, 1.525])\n",
    "        #bond angle vector, in radians, CA-C-N, C-N-CA, N-CA-C\n",
    "        self.avg_bond_angles = torch.tensor([2.034, 2.119, 1.937])\n",
    "\n",
    "    \n",
    "    def forward(self, sequences, lengths):\n",
    "        max_len = sequences.size(0)\n",
    "        batch_sz = sequences.size(1)\n",
    "        lengths = torch.tensor(lengths, dtype=torch.long, requires_grad=False)\n",
    "        order = [x for x,y in sorted(enumerate(lengths), key=lambda x: x[1], reverse=True)]\n",
    "        \n",
    "        abs_pos = torch.tensor(range(max_len), dtype=torch.float32).unsqueeze(1)\n",
    "        abs_pos = (abs_pos * torch.ones((1, batch_sz))).unsqueeze(2)\n",
    "        \n",
    "        h0 = Variable(torch.zeros((self.num_layers*2, batch_sz, self.hidden_size)))\n",
    "        c0 = Variable(torch.zeros((self.num_layers*2, batch_sz, self.hidden_size)))\n",
    "        \n",
    "        #set sequence input type\n",
    "        if self.input_type == 'onehot':\n",
    "            sequences = torch.tensor(sequences, dtype=torch.float32, requires_grad=True)\n",
    "            pad_seq = torch.cat([sequences, abs_pos], 2)\n",
    "        elif self.input_type == 'tokens':\n",
    "            sequences = torch.tensor(sequences, dtype=torch.long, requires_grad=False)\n",
    "            pad_seq = self.embeds(sequences)\n",
    "            pad_seq = torch.cat([pad_seq, abs_pos], 2)\n",
    "    \n",
    "        packed = pack_padded_sequence(pad_seq[:, order], lengths[order], batch_first=False)\n",
    "        \n",
    "        lstm_out, _ = self.lstm(packed, (h0,c0))\n",
    "        unpacked, _ = pad_packed_sequence(lstm_out, batch_first=False, padding_value=0.0)\n",
    "        unpacked = unpacked[:, range(batch_sz)] #reorder to match target\n",
    "\n",
    "        if self.model_type == 'hardtanh':\n",
    "            flat = unpacked.view(-1, unpacked.size(2))\n",
    "            sin_out = self.hardtanh(self.bn1(self.linear1(flat))).view(max_len, batch_sz, 3)\n",
    "            cos_out = self.hardtanh(self.bn2(self.linear2(flat))).view(max_len, batch_sz, 3)\n",
    "            out = torch.atan2(sin_out, cos_out)\n",
    "            out.register_hook(self.save_grad('out'))\n",
    "        elif self.model_type == 'alphabet':\n",
    "            softmax_out = F.softmax(self.linear(unpacked), dim=2)\n",
    "            sine = torch.matmul(softmax_out, torch.sin(self.alphabet))\n",
    "            cosine = torch.matmul(softmax_out, torch.cos(self.alphabet))\n",
    "            out = torch.atan2(sine, cosine)\n",
    "        \n",
    "        #create as many copies of first residue as there are samples in the batch\n",
    "        broadcast = torch.ones((batch_sz, 3))\n",
    "        pred_coords = torch.stack([self.A*broadcast, self.B*broadcast, self.C*broadcast])\n",
    "        \n",
    "        for ix, triplet in enumerate(out[1:]):\n",
    "            pred_coords = geometric_unit(pred_coords, triplet, \n",
    "                                         self.avg_bond_angles, \n",
    "                                         self.avg_bond_lens)\n",
    "        #pred_coords.register_hook(self.save_grad('pc'))\n",
    "        \n",
    "            \n",
    "        #pdb.set_trace()\n",
    "        return pred_coords\n",
    "    \n",
    "    def save_grad(self, name):\n",
    "        def hook(grad): self.grads[name] = grad\n",
    "        return hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, torch.Size([382, 32, 41]), torch.Size([1146, 32, 3]), torch.Size([1146, 32, 3]))\n",
      "(1, torch.Size([450, 32, 41]), torch.Size([1350, 32, 3]), torch.Size([1350, 32, 3]))\n",
      "(2, torch.Size([731, 32, 41]), torch.Size([2193, 32, 3]), torch.Size([2193, 32, 3]))\n",
      "(3, torch.Size([622, 32, 41]), torch.Size([1866, 32, 3]), torch.Size([1866, 32, 3]))\n"
     ]
    }
   ],
   "source": [
    "#make sure output size and target sizes are the same\n",
    "for i_batch, sampled_batch in enumerate(trn_data):\n",
    "    inp_seq = sampled_batch['sequence']\n",
    "    inp_lens = sampled_batch['length']\n",
    "    rgn = RGN(20, 1, 'hardtanh', encoding)\n",
    "    out = rgn(inp_seq, inp_lens)\n",
    "    print(i_batch, inp_seq.size(), sampled_batch['coords'].size(), out.size())\n",
    "    \n",
    "    if i_batch == 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgn = RGN(500, 1, 'hardtanh', encoding)\n",
    "#rgn.load_state_dict(torch.load(data_path+'models/rgn_no_bn.pt')) #load pretrained model\n",
    "optimizer = torch.optim.Adam(rgn.parameters(), lr=1e-3)\n",
    "drmsd = dRMSD()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next steps, try debugging gradient using https://gist.github.com/apaszke/f93a377244be9bfcb96d3547b9bc424d."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:36,  9.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train Loss 39.637737751\n",
      "Finished Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "running_loss = 0.0\n",
    "\n",
    "for epoch in range(1):\n",
    "    last_batch = len(trn_data) - 1\n",
    "    for i, data in tqdm(enumerate(trn_data)):\n",
    "        names = data['name']\n",
    "        coords = data['coords']\n",
    "        mask = data['mask']\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = rgn(data['sequence'], data['length'])\n",
    "\n",
    "        loss = drmsd(outputs, coords, mask)\n",
    "\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(rgn.parameters(), max_norm=50)\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if (i != 0) and (i % last_batch == 0):\n",
    "            print('Epoch {}, Train Loss {}'.format(epoch, running_loss/i))\n",
    "            running_loss = 0.0\n",
    "            break\n",
    "    \"\"\"\n",
    "    last_batch = len(val_data) - 1\n",
    "    for i, data in tqdm(enumerate(val_data)):\n",
    "        names = data['name']\n",
    "        coords = data['coords']\n",
    "        mask = data['mask']\n",
    "        \n",
    "        outputs = rgn(data['sequence'], data['length'])\n",
    "        loss = drmsd(outputs, coords, mask)\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if (i != 0) and (i % last_batch == 0):\n",
    "            print('Epoch {}, Val Loss {}'.format(epoch, running_loss/i))\n",
    "            running_loss = 0.0\n",
    "    \"\"\"\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(rgn.state_dict(), data_path+'models/rgn_no_bn.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda2]",
   "language": "python",
   "name": "conda-env-anaconda2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
